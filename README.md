# DATA ENGINEER WORKSHOP  
--------------------------
## Workshop 1_Data Collection with python
Use `PyMySQL` Package to connect the `MySQL` database to `Python` for the purpose of data collection.Then, in order to make it simpler for users and improve the aesthetics of the tables, we changed it to `Pandas`. The tables (Employees & Jobs) were then joined and used the `Requests` package to obtain data from `REST APIs` in addition to a standard MySQL database. Finally, Saved the tables as a `CSV file`.
## Workshop 2_Data Cleansing with Pyspark
Clean and prepare are the part of data cleansing. Using Python's `PySpark` package, apply Spark in this cleaning process. First is prepare Python's environment. Loaded data into Spark after PySpark has been installed in Python. Then, Profiled the data to understand the various details of each column, including the count, mean, standard deviation, minimum and maximum. After that, we completed a sematic anomalies (such as rectifying the outlier) and a syntactical abnormalities (such as filling the null value). Finally, Saved the cleansed data as `CSV files`.
